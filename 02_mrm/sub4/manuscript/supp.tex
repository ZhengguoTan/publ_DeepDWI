\documentclass[a4paper,11pt,twoside]{report}
\usepackage[utf8]{inputenc}
\usepackage[top=2.5cm,bottom=2.5cm,outer=2.5cm,inner=2.0cm]{geometry}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[noabbrev,capitalise]{cleveref}
\usepackage{colortbl}
\usepackage{color,soul}
\usepackage{xcolor}

\usepackage{enumitem}
% \setlist[enumerate,1]{label=\color{blue}(\arabic*)}
\setlist[enumerate,1]{label=(\arabic*)}

\usepackage{graphicx}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{hyperref}
\hypersetup{
	colorlinks = true,
	linkbordercolor = {white},
}

\usepackage{listings}
\usepackage{titlesec}
\usepackage{setspace}
\renewcommand{\baselinestretch}{1.3}

\usepackage{siunitx}
\usepackage{threeparttable}
\usepackage{multirow}
\usepackage[super]{nth}

%\renewcommand{\figurename}{SI Figure}
\renewcommand{\thefigure}{S\arabic{figure}}

%\renewcommand{\tablename}{Supporting Information Table}
\renewcommand{\thetable}{S\arabic{table}}

\renewcommand{\thesection}{\arabic{section}}
\titleformat*{\section}{\large\bfseries}

\renewcommand\contentsname{}

\begin{document}
	
	\noindent {\large\textbf{Supplementary Information}}
	
	\vspace{1em}
	
	\begin{center}
		{\Large High-Resolution Diffusion-Weighted Imaging with Self-Gated Self-Supervised Unrolled Reconstruction}
	\end{center}
	
	\begin{center}
		Zhengguo Tan, Patrick A. Liebig, Annika Hofmann, Frederik B. Laun, Florian Knoll
	\end{center}
	
	\begingroup
	\let\clearpage\relax
	\tableofcontents
	\endgroup
	
	\vfill
	\pagebreak

	% ========= ResNet
	\section{Residual Neural Network (ResNet)}
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.65\textwidth]{figures/figS1.png}
		\caption{The architecture of ResNet. $x$ and $y$ denotes the shape of diffusion-weighted images, 
			$d$ denotes the number of diffusion encodings, and $2$ indicates the real and the imaginary part.}
		\label{FIGS:archi}
	\end{figure}
	
	In this study, the acquisition base resolution is 286, i.e., $x=y=286$. 
	The ResNet architecture in \cref{FIGS:archi} consists of $3,786,539$ trainable parameters.
	
	
	\vfill
	\pagebreak
	
	% ========= Ablation study
	\section{Ablation Study}
	
	In machine learning, ablation means the removal of a component of an artificial intelligence (AI) system. 
	Here, we replace the ResNet with an Identity module (\colorbox{yellow}{torch.nn.Identity()}), 
	which returns its input without any modification or computation, and has no trainable parameter. 
	As a reuslt, only the regularization parameter $\lambda$ remains trainable during ADMM unrolling.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=\textwidth]{figures/figS2.png}
		\caption{Ablation study. 
			(\nth{1} Row) Reconstruction results of the proposed ADMM unrolling with the ResNet architecture.
			(\nth{2} Row) Reconstruction results of ADMM unrolling without ResNet, but the Identity operator as the regularization.}
		\label{FIGS:ablation}
	\end{figure}
	
	\cref{FIGS:ablation} displays the reconstruction results of the designed ablation study. 
	This ablation study demonstrates the important role of the learned ResNet as a regularizer 
	in removing noise while retaining sharp diffusion-weighted contrasts.
	
	\vfill
	\pagebreak
	
	\section{Generalizability: Cross Subjects}
	
	While Figure 4 in the main text shows the cross-slice generalizability of the proposed ADMM unrolling method,
	here we try to investigate whether the method generalizes among subjects. 
	Specificially, we use the checkpoint from \cref{FIGS:ablation} for the reconstruction of the data in Figure 4.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=\textwidth]{figures/figS3.png}
		\caption{Cross-subject generalizability. 
			(\nth{1} Column) Training and inference with the same subject, but only one slice is used for training.
			(\nth{2} Column) Training and inference with difference subjects. 
			Here, training is performed with the data in \cref{FIGS:ablation}, 
			whereas inference is performed on a different subject.
			(\nth{3} Column) Subtration of diffusion-weighted images 
			in the \nth{1} column from those in the \nth{2} column.}
		\label{FIGS:intersubject}
	\end{figure}
	
	\cref{FIGS:intersubject} shows the results of the cross-subject generalizability study. 
	The difference images show only subtle differences between the two reconstruction results: 
	cross-slice and cross-subject inferences. 
	The proposed ADMM unrolling method generalizes well cross slices and subjects. 
	We foresee that ADMM unrolling with the self-supervised training can serve 
	as a generalized model for diffusion-weighted image reconstruction and for fast inference.
	
	\vfill
	\pagebreak
	
	% ========= Reconstruction time
	\section{Reconstruction Time}
	
	\newcolumntype{a}{p{0.23\textwidth}}
	\newcolumntype{b}{p{0.35\textwidth}}
	\begin{table}[ht]
		\centering
		\caption{Comparison of reconstruction times per multi-band slice. 
			All reconstructions were performed on GPU A100 with 80GB memory.}

		\begin{tabular}{a b b}
			\toprule
			Method & Training time (\si{\hour}) & Inference time (\si{\minute}) \\
			\hline
			MUSE & - & 02:08 \\
			LLR & - & 54:00 \\
			ADMM Unroll & 04:27 & 01:50 \\
			\bottomrule
		\end{tabular}
	\end{table}

	
\end{document}